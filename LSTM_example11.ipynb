{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iakovkh/mypython/blob/main/LSTM_example11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration Section\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Adjustable parameters\n",
        "normalize_data = False\n",
        "number_of_layers = 3\n",
        "number_of_neurons = 20\n",
        "optimizer = 'adam'\n",
        "loss_function = 'mean_squared_error'\n",
        "activation = 'relu'\n",
        "epochs = 100\n",
        "tolerance = 0.01\n",
        "\n",
        "# Step I - General data preparation\n",
        "class MyMatrix:\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "\n",
        "    # 1.12 Method to read data from xlsx file\n",
        "    def read_data_from_file(self, file_path):\n",
        "        self.data = pd.read_excel(file_path)\n",
        "\n",
        "    # 1.13 Method to normalize data\n",
        "    def normalize_data(self):\n",
        "        scaler = MinMaxScaler()\n",
        "        self.data = pd.DataFrame(scaler.fit_transform(self.data), columns=self.data.columns)\n",
        "\n",
        "    # 1.14 Method to display data in console\n",
        "    def display_console(self, column=None):\n",
        "        if column:\n",
        "            print(self.data[column])\n",
        "        else:\n",
        "            print(self.data)\n",
        "\n",
        "    # 1.15 Method to display data visually\n",
        "    def display_visual(self, column=None):\n",
        "        if column:\n",
        "            plt.figure()\n",
        "            plt.plot(self.data[column])\n",
        "            plt.title(f'Column: {column}')\n",
        "            plt.show()\n",
        "        else:\n",
        "            for col in self.data.columns:\n",
        "                plt.figure()\n",
        "                plt.plot(self.data[col])\n",
        "                plt.title(f'Column: {col}')\n",
        "                plt.show()\n",
        "\n",
        "# Step II - Read and prepare data\n",
        "# 2.1 Create an object of MyMatrix class\n",
        "MyData = MyMatrix()\n",
        "\n",
        "# 2.2 Read the data from the file\n",
        "MyData.read_data_from_file('/content/sample_data/NN.xlsx')\n",
        "\n",
        "# 2.3 Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(MyData.data, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2.4 Normalize the data if required\n",
        "if normalize_data:\n",
        "    MyData.normalize_data()\n",
        "\n",
        "# Step III - Design the neural network\n",
        "# 3.2 Create a back propagation neural network\n",
        "model = Sequential()\n",
        "model.add(Dense(number_of_neurons, input_dim=train_data.shape[1] - 1, activation=activation))\n",
        "for _ in range(number_of_layers - 2):\n",
        "    model.add(Dense(number_of_neurons, activation=activation))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function)\n",
        "\n",
        "# Separate input features and target variable\n",
        "X_train = train_data.iloc[:, 1:].values\n",
        "y_train = train_data.iloc[:, 0].values\n",
        "X_test = test_data.iloc[:, 1:].values\n",
        "y_test = test_data.iloc[:, 0].values\n",
        "\n",
        "# 3.3 Train the network\n",
        "history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), verbose=1)\n",
        "\n",
        "# Step IV - Testing results\n",
        "# 4.1 Use the trained neural network to forecast values\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# 4.2 Visualize forecasted values and compare them to actual values\n",
        "plt.figure()\n",
        "plt.plot(y_test, label='Actual')\n",
        "plt.plot(predictions, label='Predicted')\n",
        "plt.legend()\n",
        "plt.title('Actual vs Predicted Values')\n",
        "plt.show()\n",
        "\n",
        "# 4.3 Test segment to read and predict new data\n",
        "def test_new_data(file_path):\n",
        "    new_data = pd.read_excel(file_path)\n",
        "    if normalize_data:\n",
        "        scaler = MinMaxScaler()\n",
        "        new_data = pd.DataFrame(scaler.fit_transform(new_data), columns=new_data.columns)\n",
        "    X_new = new_data.iloc[:, 1:].values\n",
        "    predictions_new = model.predict(X_new)\n",
        "    print(predictions_new)\n",
        "\n",
        "# Test the model with new data\n",
        "test_new_data('/content/sample_data/NN_validate.xlsx')\n"
      ],
      "metadata": {
        "id": "K1w3qb9b_WfW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}